# Alphabet_Soup_Funding

## Challenge writeup
- For my deep neural network, I used 3 layers each using 2/3 the number of columns neurons. I tried one and two layers with various combinations of neuron amounts including 2x, 1.5x, and the same number of columns. I went with this one because it was the most efficient and produced the desired test accuracy. My final model was trained using 30 epochs and produced a 75.06% accuracy, when I ran it on the test data the accuracy was still 75.06%. To get it to this level, besides testing different layers and neurons, I had to consider different features and bucketing. In my original model I dropped the name column, but doing so did not produce the desired accuracy so I went back and kept it in my features. In terms of bucketing, I applied bucketing to Application type (reduced it from 17 to 8 unique values), Classification (reduced from 71 to 12 columns), and name (reduced from 19568 to 22 columns). It took a few different bucketing thresholds on the name column to produce desired accuracy. If I were to use a different model to classify, I would probably start with and SVM supervised machine model. This model is good at handling different data types, are good for creating regression using two groups, and are also less prone to overfitting.